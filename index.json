[{"content":"Introduction UFW or Uncomplicated Firewall is a simplified CLI firewall management tool. It is easy to use since it hide the complexity of iptables. It is also easy to configure since it has a simple syntax and suitable for controlling firewall from shell scripts. UFW can be used to allow or deny connections based on various criteria, such as source and destination IP addresses, ports, and protocols.\nThe problem is when we install Docker, it will install two custom chains in the iptables: DOCKER and DOCKER-USER. It ensure all incoming packets are always checked by these chains first. In orther words, Docker will bypass all the rules that we set in the ufw chain and our published ports can be accessed from anywhere.\nTo overcome this problem, we can disable docker\u0026rsquo;s iptables rules configuration option by adding the --iptables=false to the docker daemon but this also means that we have to give up docker\u0026rsquo;s network management system which is a big deal. All containers can not access the external network anymore!\nWe can maintain the iptables by manually add rules but it is a tedious task and not recommended since it requires a lot of knowledge about iptables. This is not what we want and here is where ufw-docker comes in.\nUFW-Docker is an open source solution for securely using Docker and UFW together. It provides a framework for managing UFW rules and allows users to create their own sets of rules by combining existing rules. It also provides a way to ensure that Docker containers are running securely while still allowing access to the ports that they need.\nNow let\u0026rsquo;s get started with UFW first to understand how it works and then we will move on to UFW-Docker.\nufw Ufw should be installed by default on Ubuntu systems. If not, you can install it with:\nsudo apt install ufw By default, ufw is disabled. Just to make sure, you can check the status with:\nsudo ufw status It should return:\n Status: inactive\n Now let\u0026rsquo;s block all incoming traffic.\nsudo ufw default deny incoming Now if we enable the firewall, all incoming traffic will be blocked. But be mindful that if you\u0026rsquo;re using ssh, you will not be able to access the server anymore. So let\u0026rsquo;s allow ssh first.\nsudo ufw allow ssh In some cases, you may want to allow http and https ports as well.\nsudo ufw allow http sudo ufw allow https Now we can safely enable the firewall.\nsudo ufw enable Let\u0026rsquo;s check the status again. Now with extra verbose flag.\nsudo ufw status verbose It should return:\n$ sudo ufw status verbose Status: active Logging: on (low) Default: deny (incoming), allow (outgoing), deny (routed) New profiles: skip To Action From -- ------ ---- 22/tcp ALLOW IN Anywhere 80/tcp ALLOW IN Anywhere 443/tcp ALLOW IN Anywhere 22/tcp (v6) ALLOW IN Anywhere (v6) 80/tcp (v6) ALLOW IN Anywhere (v6) 443/tcp (v6) ALLOW IN Anywhere (v6) You definitely will want to delete some rules later. So let\u0026rsquo;s take a look at the rule numbers. Basically the same output as above prefixed with rule numbers.\nsudo ufw status numbered To delete a rule, you can use the following command substituting the rule number with the one you want to delete.\nsudo ufw delete \u0026lt;rule number\u0026gt; Ufw allows you to specify a port and an IP address to allow incoming traffic to. This is useful if you want to allow incoming traffic to a specific port from a specific IP address.\nsudo ufw route allow from $EXTERNAL_IP to $CONTAINER_IP port \u0026lt;port\u0026gt; comment \u0026#34;allow from $EXTERNAL_IPto $CONTAINER_IP\u0026#34; ufw-docker By now you should have a basic understanding of how ufw works. Now let\u0026rsquo;s move on to ufw-docker. First, we need to install it.\nsudo wget -O /usr/local/bin/ufw-docker \\  https://github.com/chaifeng/ufw-docker/raw/master/ufw-docker sudo chmod +x /usr/local/bin/ufw-docker ufw-docker needs to modify the configuration rules after.rules file in /etc/ufw/ directory. Please refer to their Github repo for more details.\nsudo ufw enable sudo ufw-docker install sudo systemctl restart ufw Now let\u0026rsquo;s expose a port for a container. Note that we don\u0026rsquo;t need to expose the port to our host machine. We only need to expose it to the docker network. The iptables rules will route the traffic to the container.\nsudo ufw-docker allow nginx Here nginx is the name of the container. This will essentially allow all incoming traffic to port 80 and 443 of the container nginx but it only works if the container is running under docker network. If your container is running with network-mode: host, you can use ufw allow instead. (Not recommended)\nAnd to remove it, you can use the following command.\nsudo ufw-docker remove nginx You can also specify a port to remove.\nsudo ufw-docker remove nginx 80 And that should get you started with UFW and Docker networking!\nConclusion As you can see, Docker networking is a powerful tool that allows you to create isolated networks for your containers. In this article, I showed how to configure it using UFW since it’s the most popular firewall among Ubuntu users. If you are using other operating systems like Debian or CentOS, there are similar tools available for them as well. If you have any questions or comments, feel free to leave them below.\n","permalink":"https://nguyentritai.tk/posts/2023/ufw/","summary":"Introduction UFW or Uncomplicated Firewall is a simplified CLI firewall management tool. It is easy to use since it hide the complexity of iptables. It is also easy to configure since it has a simple syntax and suitable for controlling firewall from shell scripts. UFW can be used to allow or deny connections based on various criteria, such as source and destination IP addresses, ports, and protocols.\nThe problem is when we install Docker, it will install two custom chains in the iptables: DOCKER and DOCKER-USER.","title":"UFW with Docker"},{"content":"OAuth2 The OAuth 2.0 Authorization Framework is an open-standard authorization protocol or framework that provides applications the ability for secure access to protected resources without giving them the password. The key concepts of OAuth include resource owners, clients, authorization server, access tokens, and scopes.\n Resource owners are entities capable of authorizing access to a protected resource (e.g. user). Clients are third-party applications that want access to a protected resource (e.g. application). Authorization servers are responsible for verifying authorization grants and issuing access tokens (e.g. Keycloak). Access tokens are used to access protected resources (i.e. JWT token). Scopes are used to limit the amount of access that an OAuth client has to a protected resource (e.g. read-only)  Introduction  In the traditional client-server authentication model, the client requests an access-restricted resource (protected resource) on the server by authenticating with the server using the resource owner\u0026rsquo;s credentials. In order to provide third-party applications access to restricted resources, the resource owner shares its credentials with the third party\n Limitation:\n Third-party are required to store credentials (e.g: password). Servers are required to support password authentication. Third-party has no restrictions on the resources they can access. Resource owners cannot revoke access to a third-party. Security compromise casscade down to end-user\u0026rsquo;s password and data.  Instead of using resource owner\u0026rsquo;s credentials, OAuth uses access tokens to access protected resources. Access tokens are issued by the authorization server and are short-lived. Access tokens are NOT used to authenticate the client, but instead are used to identify the client and authorize access to the protected resource.\nProtocol Flow +--------+ +---------------+ | |--(A)- Authorization Request -\u0026gt;| Resource | | | | Owner | | |\u0026lt;-(B)-- Authorization Grant ---| | | | +---------------+ | | | | +---------------+ | |--(C)-- Authorization Grant --\u0026gt;| Authorization | | Client | | Server | | |\u0026lt;-(D)----- Access Token -------| | | | +---------------+ | | | | +---------------+ | |--(E)----- Access Token ------\u0026gt;| Resource | | | | Server | | |\u0026lt;-(F)--- Protected Resource ---| | +--------+ +---------------+ Figure 1: Abstract Protocol Flow (https://datatracker.ietf.org/doc/html/rfc6749#section-1.2) OAuth Protocol Flow is the process that allows an application to request authorization to access a user’s data. It involves the user granting permission to the application, the application sending an authorization request to the authorization server, and the authorization server responding with an access token which can be used to request the user’s data. The protocol flow is divided into four steps:\n The user grants the application permission to access their data by clicking on a “Login with…” button or similar. The application then sends an authorization request to the authorization server which contains information about the application, the user, and the data the application is requesting access to. The authorization server then responds with an access token which is used to request the user’s data. The application then sends a request to the resource server with the access token, and the resource server responds with the requested data.  Grant Types Authorization grants are credentials representing the resource owner\u0026rsquo;s authorization (to access its protected resources) expressed in a specific manner, for the specific purpose of being exchanged for an access token.\nThere are four grant types:\n Authorization Code Grant: Used when the client needs to access resources that are owned by the user, such as when the user needs to log into an application or grant access to their data Implicit Grant: Used when the client needs to access resources on behalf of a user without the user having to provide credentials. Resource Owner Password Credentials Grant: Used when the client needs to access resources that are owned by the user, but the user does not need to log in or provide credentials. Client Credentials Grant: Used when the client needs to access resources that the client owns, such as when the client needs to make requests on its own behalf.  Authorization Code Grant Instead of requesting authorization directly from resource owner, the client application requests authorization from the authorization server. The authorization server authenticates the resource owner and obtains authorization. The authorization server then issues an authorization code to the client application. The client application then exchanges the authorization code for an access token.\nThe Authorization Code grant type is the most secure of the OAuth 2.0 grant types and provides the highest level of assurance that the access token is only issued to the intended client application\nImplicit Grant The Implicit Grant type is an OAuth 2.0 authorization flow that does not require an intermediate code exchange step. Instead, the client-side application directly requests an access token from the authorization server, and the authorization server directly issues the access token to the client-side application. The Implicit grant type is suitable for client-side applications (such as JavaScript apps) where the client secret can\u0026rsquo;t be securely stored. It is also used in mobile applications where the client secret is not available.\nThe Implicit grant flow is similar to the Authorization Code grant flow, except that it does not require the client to exchange an authorization code for an access token. Instead, the authorization server responds with an access token directly and can be verify via the access token\u0026rsquo;s signature.\nResource Owner Password Credentials Grant When there is a high degree of trust between the resource owner and the client (e.g. the client is part of the device), the resource owner password credentials (i.e. username and password) can be used to obtain an access token directly.\nClient Credentials Grant OAuth2 Client Credentials grant is an authorization flow used by clients to obtain an access token outside of the context of a user. In this flow, the client will send its own credentials (usually in the form of a client ID and a client secret) to the authorization server, which will then respond with an access token. This access token can then be used to access the client\u0026rsquo;s own resources, not on behalf of a user. This type of flow is typically used by applications that need to access their own APIs, such as for backend services.\nAccess Token An OAuth 2 Access Token is a string that is used to authenticate a user and grant access to an API. They are issued by an authorization server, typically after a user has successfully authenticated and given their consent to access the API. Access tokens are used to make requests to the API on behalf of the user, and usually have a limited lifetime. Access tokens may also be revoked by the user or the authorization server at any time. Access tokens are typically encoded using the JWT (JSON Web Token) format, which includes the user’s identity, the scope of the API access granted, an expiration time and other security-related information like a signature.\nRefresh Token A refresh token is a special kind of token that is used to obtain a new access token. It is issued to the client by the authorization server and is used to obtain a new access token when the current access token becomes invalid or expires.\n+--------+ +---------------+ | |--(A)------- Authorization Grant ---------\u0026gt;| | | | | | | |\u0026lt;-(B)----------- Access Token -------------| | | | \u0026amp; Refresh Token | | | | | | | | +----------+ | | | |--(C)---- Access Token ----\u0026gt;| | | | | | | | | | | |\u0026lt;-(D)- Protected Resource --| Resource | | Authorization | | Client | | Server | | Server | | |--(E)---- Access Token ----\u0026gt;| | | | | | | | | | | |\u0026lt;-(F)- Invalid Token Error -| | | | | | +----------+ | | | | | | | |--(G)----------- Refresh Token -----------\u0026gt;| | | | | | | |\u0026lt;-(H)----------- Access Token -------------| | +--------+ \u0026amp; Optional Refresh Token +---------------+ Figure 2: Refreshing an Expired Access Token (https://datatracker.ietf.org/doc/html/rfc6749#section-1.5) Clients Client registration Before initiating the protocol, the client registers with the authorization server\nIn order to register a client, client developers needs to:\n Specify client type Provide client redirect URIs  Client types There are two types of clients:\n Confidential: Clients that can keep their credentials confidential (e.g. web applications) Public: Clients that cannot keep their credentials confidential (e.g. mobile applications)  Clients can have multiple components, such as a web application and a mobile application. In this case, the client have different client types and security context and should be registered separately.\nOAuth 2.0 defines three different classes of clients:\n web applications: store the client credentials on a server (e.g. web server) user-agent-based applications: execute code within a user agent (e.g. web browser) native applications: installed on a user\u0026rsquo;s device (e.g. mobile phone or tablet)   This specification has been designed around the following client profiles:\n  web application\nA web application is a confidential client running on a web server. Resource owners access the client via an HTML user interface rendered in a user-agent on the device used by the resource owner. The client credentials as well as any access token issued to the client are stored on the web server and are not exposed to or accessible by the resource owner.\n  user-agent-based application\nA user-agent-based application is a public client in which the client code is downloaded from a web server and executes within a user-agent (e.g., web browser) on the device used by the resource owner. Protocol data and credentials are easily accessible (and often visible) to the resource owner. Since such applications reside within the user-agent, they can make seamless use of the user-agent capabilities when requesting authorization.\n  native application\nA native application is a public client installed and executed on the device used by the resource owner. Protocol data and credentials are accessible to the resource owner. It is assumed that any client authentication credentials included in the application can be extracted. On the other hand, dynamically issued credentials such as access tokens or refresh tokens can receive an acceptable level of protection. At a minimum, these credentials are protected from hostile servers with which the application may interact. On some platforms, these credentials might be protected from other applications residing on the same device.\n   Client identifier Client ID is a unique string that is used to identify the client application when it requests access to a user’s resources from an authorization server. It is used to verify that the application is registered and trusted by the authorization server, and to ensure that the application is not attempting to gain access to resources it does not have permission to access. It is also used to help the authorization server track the application’s access to the user’s resources.\nClient authentication Client Authentication is a process used to verify a client application\u0026rsquo;s identity when requesting access to a user\u0026rsquo;s resources from an authorization server. This process helps to ensure that the application is registered and trusted, and that it is not attempting to gain access to resources it does not have permission to access. The process typically involves the client application providing a unique identifier and a secret key, which the authorization server can use to authenticate the client. In addition, the authorization server may require additional authentication methods, such as a certificate or a user\u0026rsquo;s username and password.\nClient password Clients can be assigned a password that is used to authenticate the client when it requests access to a user’s. It can be used to authenticate with authorization server via the HTTP Basic authentication scheme.\n The client identifier is encoded using the \u0026ldquo;application/x-www-form-urlencoded\u0026rdquo; encoding algorithm per Appendix B, and the encoded value is used as the username; the client password is encoded using the same algorithm and used as the password\n E.g.:\n Authorization: Basic czZCaGRSa3F0Mzo3RmpmcDBaQnIxS3REUmJuZlZkbUl3  Alternatively, but NOT RECOMMENDED, the client can authenticate with the authorization server using the client_id and client_secret in the request body using:\n client_id as the username client_secret as the password  Protocol endpoints The authorization process utilizes 2 endpoints:\n Authorization endpoint: used to interact with the resource owner and obtain an authorization grant. Token endpoint: used by the client to obtain an access token by presenting its authorization grant or refresh token.  Authorization endpoint The authorization endpoint is used to interact with the resource owner and obtain an authorization grant.\nResponse types:\n code: for requesting an authorization code. token: for requesting an access token (implicit grant).  Token endpoint The token endpoint allows clients to obtain access token and refresh token. This endpoint is used with every authorization grant except for the implicit grant type (since an access token is issued directly).\nA client will usually send an authorization grant (such as an authorization code) to the token endpoint, and the endpoint will return an access token and a refresh token. The access token is used to gain access to protected resources, while the refresh token is used to obtain a new access token when the current one expires.\nThe token endpoint can also be used to revoke access tokens, and to obtain additional information about the token, such as its expiration time.\nObtaining Authorization Authorization code grant The authorization code flow involves the following steps:\n The client initiates the flow by redirecting the user to the authorization server. The user authenticates with the authorization server and grants the client access. The authorization server sends an authorization code back to the client application. The client application exchanges the authorization code for an access token. The client application can use the access token to make API requests.  +----------+ | Resource | | Owner | | | +----------+ ^ | (B) +----|-----+ Client Identifier +---------------+ | -+----(A)-- \u0026amp; Redirection URI ----\u0026gt;| | | User- | | Authorization | | Agent -+----(B)-- User authenticates ---\u0026gt;| Server | | | | | | -+----(C)-- Authorization Code ---\u0026lt;| | +-|----|---+ +---------------+ | | ^ v (A) (C) | | | | | | ^ v | | +---------+ | | | |\u0026gt;---(D)-- Authorization Code ---------\u0026#39; | | Client | \u0026amp; Redirection URI | | | | | |\u0026lt;---(E)----- Access Token -------------------\u0026#39; +---------+ (w/ Optional Refresh Token) Note: The lines illustrating steps (A), (B), and (C) are broken into two parts as they pass through the user-agent. Figure 3: Authorization Code Flow (https://datatracker.ietf.org/doc/html/rfc6749#section-4.1) Implicit grant The implicit grant flow involves the following steps:\n The client initiates the flow by redirecting the user to the authorization server. The user authenticates with the authorization server and grants the client access. The authorization server sends an access token back to the client application. The client application can use the access token to make API requests.  +----------+ | Resource | | Owner | | | +----------+ ^ | (B) +----|-----+ Client Identifier +---------------+ | -+----(A)-- \u0026amp; Redirection URI ---\u0026gt;| | | User- | | Authorization | | Agent -|----(B)-- User authenticates --\u0026gt;| Server | | | | | | |\u0026lt;---(C)--- Redirection URI ----\u0026lt;| | | | with Access Token +---------------+ | | in Fragment | | +---------------+ | |----(D)--- Redirection URI ----\u0026gt;| Web-Hosted | | | without Fragment | Client | | | | Resource | | (F) |\u0026lt;---(E)------- Script ---------\u0026lt;| | | | +---------------+ +-|--------+ | | (A) (G) Access Token | | ^ v +---------+ | | | Client | | | +---------+ Note: The lines illustrating steps (A) and (B) are broken into two parts as they pass through the user-agent. Figure 4: Implicit Grant Flow (https://datatracker.ietf.org/doc/html/rfc6749#section-4.2) Resource owner password credentials grant The resource owner password credentials grant flow involves the following steps:\n The client application requests an access token from the authorization server by providing the resource owner\u0026rsquo;s credentials. The authorization server validates the credentials and sends an access token back to the client application.  +----------+ | Resource | | Owner | | | +----------+ v | Resource Owner (A) Password Credentials | v +---------+ +---------------+ | |\u0026gt;--(B)---- Resource Owner -------\u0026gt;| | | | Password Credentials | Authorization | | Client | | Server | | |\u0026lt;--(C)---- Access Token ---------\u0026lt;| | | | (w/ Optional Refresh Token) | | +---------+ +---------------+ Figure 5: Resource Owner Password Credentials Flow (https://datatracker.ietf.org/doc/html/rfc6749#section-4.3) Client credentials grant The client credentials grant flow involves the following steps:\n The client application requests an access token from the authorization server by providing its client credentials. The authorization server validates the credentials and sends an access token back to the client application.  +---------+ +---------------+ | |\u0026gt;--(A)- Client Authentication ---\u0026gt;| | | Client | | Authorization | | |\u0026lt;--(B)---- Access Token ---------\u0026lt;| Server | | | (w/ Optional Refresh Token) | | +---------+ +---------------+ Figure 6: Client Credentials Flow (https://datatracker.ietf.org/doc/html/rfc6749#section-4.4) ","permalink":"https://nguyentritai.tk/posts/2023/oauth2/","summary":"OAuth2 The OAuth 2.0 Authorization Framework is an open-standard authorization protocol or framework that provides applications the ability for secure access to protected resources without giving them the password. The key concepts of OAuth include resource owners, clients, authorization server, access tokens, and scopes.\n Resource owners are entities capable of authorizing access to a protected resource (e.g. user). Clients are third-party applications that want access to a protected resource (e.","title":"Oauth2 - The concept"},{"content":"There are not much infomation on the internet on how to visualize your embeddings with Tensorboard. I\u0026rsquo;ve had a hard time trying to make it work properly. Although there\u0026rsquo;re some tutorial on the internet but most of them are for Tensorflow 1 and I didn\u0026rsquo;t find the Tensorboard guide documentation page much help. So here\u0026rsquo;s how I make it works and hopefully it\u0026rsquo;ll help you too. But before we continue, I\u0026rsquo;ll assume you already have an image dataset with labels and a model ready.\nOkay let\u0026rsquo;s dive in. Here\u0026rsquo;s what we\u0026rsquo;ll need to do:\n Use our model to predict the training set and take the output of embedding layer. Create a sprite image for projecting image on Tensorboard. Save the labels (and others if avalable) to a metadata.tsv file Save a tensorflow checkpoint with embedding vectors as tf.Variable  All these files must be saved in the same folder since later we\u0026rsquo;ll call Tensorboard and specify this directory as log_dir for it to find the necessary files.\nFeature extract model First create your model and load the appropriate weight. Mine is just a pretrain ResNet50 with an additional dense layer with 64 neurons as my embedding layer.\nmodel = create_model(cfg) log_dir = \u0026#39;embedding_log\u0026#39; ckpt_path = tf.train.latest_checkpoint(\u0026#39;./checkpoints/ckpt0\u0026#39;) if ckpt_path is not None: print(\u0026#34;Load ckpt from {}\u0026#34;.format(ckpt_path)) model.load_weights(ckpt_path).expect_partial() else: raise ValueError(\u0026#34;No ckpt found\u0026#34;) Next we\u0026rsquo;ll save the model embedding vectors for future runs. Here I\u0026rsquo;ll loop through the train dataset, predict on a batch of images and then save the embedding vectors, labels and images to their appropriate list. If you have the labels and images ready, you can just call model.predict(train_dataset) directly. It\u0026rsquo;ll process the whole dataset and output an embedding matrix. This way, you don\u0026rsquo;t have to loop through the dataset like I do here.\nimage_list = [] label_list = [] embedding_list = [] for batch in tqdm(train_dataset, total=steps_per_epoch + 1): images, labels = batch[0] embeddings = model.predict((images, labels)) embedding_list.append(embeddings) label_list.append(np.argmax(labels, axis=1)) image_list.append(images.numpy() * 255) embeddings = np.concatenate(embedding_list, axis=0) labels = np.concatenate(label_list, axis=0) images = np.concatenate(image_list, axis=0) # Should save these for future runs # Use an if-else block to check if the files exist # So you don\u0026#39;t have to loop through the dataset every run. np.save(os.path.join(log_dir, \u0026#39;embeddings.npy\u0026#39;), embeddings) print(\u0026#34;Saved embeddings to {}\u0026#34;.format(os.path.join(log_dir, \u0026#39;embeddings.npy\u0026#39;))) np.save(os.path.join(log_dir, \u0026#39;labels.npy\u0026#39;), labels) print(\u0026#34;Saved labels to {}\u0026#34;.format(os.path.join(log_dir, \u0026#39;labels.npy\u0026#39;))) np.save(os.path.join(log_dir, \u0026#39;images.npy\u0026#39;), images) print(\u0026#34;Saved images to {}\u0026#34;.format(os.path.join(log_dir, \u0026#39;images.npy\u0026#39;))) print(\u0026#34;Embeddings shape: {}\u0026#34;.format(embeddings.shape)) print(\u0026#34;Labels shape: {}\u0026#34;.format(labels.shape)) print(\u0026#34;Images shape: {}\u0026#34;.format(images.shape)) \u0026gt;\u0026gt;\u0026gt; Embeddings shape: (100, 64) \u0026gt;\u0026gt;\u0026gt; Labels shape: (100, ) \u0026gt;\u0026gt;\u0026gt; Images shape: (100, 256, 256, 3) $ ls -alh embedding_log/ drwxr-xr-x 3 nttai nttai 4.0K Jun 11 15:00 . drwxrwxr-x 18 nttai nttai 4.0K Jun 10 10:23 .. -rw-r--r-- 1 nttai nttai 7.5M Jun 10 10:24 embeddings.npy -rw-r--r-- 1 nttai nttai 45G Jun 10 10:27 images.npy -rw-r--r-- 1 nttai nttai 481K Jun 10 10:27 labels.npy Sprite image Next we\u0026rsquo;ll have to create a sprite image so that when we project its embedding vector onto three dimensional space, Tensorboard will use these thumbnails we create instead of just a bunch of dots. Just make sure that the indexes stay the same.\nKeep in mind that Tensorboard only accept sprite image with maximum dimension of 8192x8192 pixels so you should select only a subset of the training set. Here, since my train_dataset only have 100 images, I\u0026rsquo;ll save each thumbnail with size of 256x256 pixels.\ndef images_to_sprite(images, log_dir, size): one_square_size = int(np.ceil(np.sqrt(len(images)))) master_width = size * one_square_size master_height = size * one_square_size spriteimage = Image.new( mode=\u0026#39;RGBA\u0026#39;, size=(master_width, master_height), color=(0, 0, 0, 0) ) print(\u0026#34;Writing sprite image to {}\u0026#34;.format( os.path.join(log_dir, \u0026#39;sprite.jpg\u0026#39;))) for count, image in tqdm(enumerate(images), total=len(images)): div, mod = divmod(count, one_square_size) h_loc = size * div w_loc = size * mod image = image.squeeze() image = Image.fromarray(image.astype(np.uint8)).resize((size, size)) spriteimage.paste(image, (w_loc, h_loc)) spriteimage.convert(\u0026#39;RGB\u0026#39;).save(f\u0026#39;{log_dir}/sprite.jpg\u0026#39;, transparency=0) thumbnail_size = 256 images_to_sprite(images, log_dir, thumbnail_size)  Fashion sprite image   $ ls -alh embedding_log/ drwxr-xr-x 3 nttai nttai 4.0K Jun 11 15:00 . drwxrwxr-x 18 nttai nttai 4.0K Jun 10 10:23 .. -rw-r--r-- 1 nttai nttai 7.5M Jun 10 10:24 embeddings.npy -rw-r--r-- 1 nttai nttai 45G Jun 10 10:27 images.npy -rw-r--r-- 1 nttai nttai 481K Jun 10 10:27 labels.npy -rw-r--r-- 1 nttai nttai 144K Jun 11 15:00 sprite.jpg Metadata to tsv file If you have class names or image ids and you want to display it rather than its class label you can write those as another column. Note that when there\u0026rsquo;re more than one column, you\u0026rsquo;re required to write the column labels as the first row, separated by tabs like so.\nlabel name image_path 1 0 cat images/cat/1.jpg 2 1 dog images/dog/1.jpg 3 1 dog images/dog/2.jpg ... ... ... ... Since I only have image labels, I\u0026rsquo;ll use the writerows() method of python csv package.\nwith open(f\u0026#39;{log_dir}/metadata.tsv\u0026#39;, \u0026#39;w\u0026#39;) as fw: csv_writer = csv.writer(fw, delimiter=\u0026#34;\\t\u0026#34;) csv_writer.writerows(np.expand_dims(labels, axis=1)) print(\u0026#34;Labels saved to {}\u0026#34;.format(os.path.join(log_dir, \u0026#39;metadata.tsv\u0026#39;))) Values inside metadata.tsv should look something like this.\n2304 1\t865 2\t3224 3\t1440 4\t3122 5\t4285 6\t334 7\t5282 8\t1744 9\t1026 10\t6774 ... ... $ ls -alh embedding_log/ drwxr-xr-x 3 nttai nttai 4.0K Jun 11 15:00 . drwxrwxr-x 18 nttai nttai 4.0K Jun 10 10:23 .. -rw-r--r-- 1 nttai nttai 7.5M Jun 10 10:24 embeddings.npy -rw-r--r-- 1 nttai nttai 45G Jun 10 10:27 images.npy -rw-r--r-- 1 nttai nttai 481K Jun 10 10:27 labels.npy -rw-r--r-- 1 nttai nttai 585 Jun 11 15:00 metadata.tsv -rw-r--r-- 1 nttai nttai 144K Jun 11 15:00 sprite.jpg Embedding checkpoint Now create a tf.Variable with the embeddings we extracted above and save it to the same log_dir directory.\nembeddings = tf.Variable(embeddings, name=\u0026#39;embeddings\u0026#39;) checkpoint = tf.train.Checkpoint(embedding=embeddings) checkpoint.save(os.path.join(log_dir, \u0026#34;embedding.ckpt\u0026#34;)) $ ls -alh embedding_log/ drwxr-xr-x 3 nttai nttai 4.0K Jun 11 15:00 . drwxrwxr-x 18 nttai nttai 4.0K Jun 10 10:23 .. -rw-r--r-- 1 nttai nttai 89 Jun 11 15:00 checkpoint -rw-r--r-- 1 nttai nttai 13K Jun 11 15:00 embedding.ckpt-1.data-00000-of-00001 -rw-r--r-- 1 nttai nttai 264 Jun 11 15:00 embedding.ckpt-1.index -rw-r--r-- 1 nttai nttai 7.5M Jun 10 10:24 embeddings.npy -rw-r--r-- 1 nttai nttai 45G Jun 10 10:27 images.npy -rw-r--r-- 1 nttai nttai 481K Jun 10 10:27 labels.npy -rw-r--r-- 1 nttai nttai 585 Jun 11 15:00 metadata.tsv -rw-r--r-- 1 nttai nttai 144K Jun 11 15:00 sprite.jpg Projector config The last thing we\u0026rsquo;ll need is the Tensorboard projector config file which specify:\n  The tensor_name. Don\u0026rsquo;t use embeddings.name, hardcode this line like below. Otherwise it\u0026rsquo;ll only project a dot for each image.\n  Name of our metadata file.\n  Name of our sprite image.\n  And specify the size of each thumbnail. Tensorboard will use this to split up each of our thumbnails using the sprite image.\n  from tensorboard.plugins import projector config = projector.ProjectorConfig() embedding = config.embeddings.add() # NOTE: Hardcode this line embedding.tensor_name = \u0026#39;embedding/.ATTRIBUTES/VARIABLE_VALUE\u0026#39; embedding.metadata_path = \u0026#39;metadata.tsv\u0026#39; embedding.sprite.image_path = \u0026#39;sprite.jpg\u0026#39; embedding.sprite.single_image_dim.extend([thumbnail_size, thumbnail_size]) projector.visualize_embeddings(log_dir, config) projector_config.pbtxt file should contain these fields.\nembeddings { tensor_name: \u0026#34;embedding/.ATTRIBUTES/VARIABLE_VALUE\u0026#34; metadata_path: \u0026#34;metadata.tsv\u0026#34; sprite { image_path: \u0026#34;sprite.jpg\u0026#34; single_image_dim: 256 single_image_dim: 256 } } $ ls -alh embedding_log/ drwxr-xr-x 3 nttai nttai 4.0K Jun 11 15:00 . drwxrwxr-x 18 nttai nttai 4.0K Jun 10 10:23 .. -rw-r--r-- 1 nttai nttai 89 Jun 11 15:00 checkpoint -rw-r--r-- 1 nttai nttai 13K Jun 11 15:00 embedding.ckpt-1.data-00000-of-00001 -rw-r--r-- 1 nttai nttai 264 Jun 11 15:00 embedding.ckpt-1.index -rw-r--r-- 1 nttai nttai 7.5M Jun 10 10:24 embeddings.npy -rw-r--r-- 1 nttai nttai 45G Jun 10 10:27 images.npy -rw-r--r-- 1 nttai nttai 481K Jun 10 10:27 labels.npy -rw-r--r-- 1 nttai nttai 585 Jun 11 15:00 metadata.tsv -rw-r--r-- 1 nttai nttai 197 Jun 11 15:00 projector_config.pbtxt -rw-r--r-- 1 nttai nttai 144K Jun 11 15:00 sprite.jpg The result Now that we have all required files, let\u0026rsquo;s run Tensorboard in this directory and checkout the result.\n$ tensorboard --logdir embedding_log/ ... TensorBoard 2.9.0 at http://localhost:6006/ (Press CTRL+C to quit) Open your browser and go to http://localhost:6006 and it should look some thing like this.\n Tensorboard Projector with 100 images     ","permalink":"https://nguyentritai.tk/posts/2022/tensorboard-projector-image-visualizer/","summary":"There are not much infomation on the internet on how to visualize your embeddings with Tensorboard. I\u0026rsquo;ve had a hard time trying to make it work properly. Although there\u0026rsquo;re some tutorial on the internet but most of them are for Tensorflow 1 and I didn\u0026rsquo;t find the Tensorboard guide documentation page much help. So here\u0026rsquo;s how I make it works and hopefully it\u0026rsquo;ll help you too. But before we continue, I\u0026rsquo;ll assume you already have an image dataset with labels and a model ready.","title":"Tensorboard Projector Image Visualizer with Tensorflow 2"},{"content":"Convolution is one of the fundamental building block of Deep Neural Network (DNN) but sometimes, it can be extremely expensive to compute since it brings a lots of parameters and we are running risk of overfiting. This is where depthwise separable convolution can be used to reduce the total number of parameters, as a result, speed up convolution. This is a form of factorized convolutions which factorize a standard convolution into a depthwise convolution and a 1 x 1 convolution called a pointwise convolution.\nWhat is Depthwise Separable Convolution? Depthwise separable convolution first use the depthwise convolution to applies a single filter to each input channel. Then the pointwise convolution is used to applies a 1 x 1 convolution to combine the outputs of the depthwise convolution. This differ from the standard convolution since it both filters and combines inputs into a new set of outputs in one step, thus more expensive in computation.\nThis depthwise separable convolution splits this into two layers, a separate layer for filtering and a separate layer for combining. This factorization has the effect of drastically reducing computation and model size.\nStandard convolution A standard convolution layer takes as input a $D_F \\times D_F \\times M$ feature map $F$ and produces a $D_F \\times D_F \\times N$ feature map $G$ where $D_F$ is the spatial width and height of a square input feature map (assume that the output feature map has the same spatial dimensions as the input and both feature maps are square), $M$ is the number of input channels (input depth), and $N$ is the number of output channel (output depth).\nThe standard convolutional layer is parameterized by convolution kernel $K$ of size $D_K \\times D_K \\times M \\times N$ where $D_K$ is the spatial dimension of the kernel assumed to be square and $M$ is the number of input channels and $N$ is the number of output channels.\nThe output feature map for standard convolution assuming stride of one and padding is computed as: $$ G_{k,l,n} = \\sum_{i,j,n} K_{i,j,m,n} \\cdot F_{k+i-1,l+j-1,m} $$\nstandard convolutions have the computational cost of: $$ D_K \\cdot D_K \\cdot D_F \\cdot D_F \\cdot M \\cdot N $$\nThat is, for one convolution operation, the number of multiplications is the number of elements in that kernel so that would be $D_K \\times D_K \\times M$ multiplications. But we slide this kernel over the input, we perform $D_K$ convolutions along the width and $D_K$ convolutions along the height and hence $D_K \\times D_K$ convolutions over all. So the number of multiplications in the convolution of one kernel over the entire input $F$ is: $$ D_K \\cdot D_K \\cdot D_F \\cdot D_F \\cdot M $$ Now this is just one kernel but if we have $N$ such kernels which makes the absolute total number of multiplications become: $$ D_K \\cdot D_K \\cdot D_F \\cdot D_F \\cdot M \\cdot N $$\nDepthwise convolution The standard convolution operation has the effect of filtering features based on the convolutional kernels and combining features in order to produce a new representation. The filtering and combination steps can be split into two steps via the use of factorized convolutions called depthwise separable convolutions for substantial reduction in computational cost.\nDepthwise separable convolution are made up of two layers: depthwise convolution and pointwise convolutions. The depthwise convolution to apply a single filter per each input channel (input depth). Pointwise convolution, a simple 1 x 1 convolution, is then used to create a linear combination of the output of the depthwise layer.\nFirst it uses depthwise convolutions to break the interaction between the number of output channels and the size of the kernel. Depthwise convolution with one filter per input channel (input depth) can be written as: $$ \\hat G_{k,l,m} = \\sum_{i,j} \\hat K_{i,j,m} \\cdot F_{k+i-1,l+j-1,m} $$\nWhere $\\hat{K}$ is the depthwise convolutional kernel of size $D_K \\times D_K \\times M$ where the $m^{th}$ filter in $\\hat{K}$ is applied to the $m^{th}$ channel in $F$ to produce the $m^{th}$ channel of the filtered output feature map $\\hat{G}$.\nDepthwise convolution has a computational cost of: $$ D_K \\cdot D_K \\cdot D_F \\cdot D_F \\cdot M $$\nFor depthwise convolution we use filters or kernels of shape $D_K \\times D_K \\times 1$ here it has a depth of one because this convolution is only applied to a channel, unlike standard convolution which is applied throughout the entire depth. Since we apply one kernel to a single input channel, we require $M$ such $D_K \\times D_K \\times 1$ over the entire input volume $F$ for each of these $M$ convolutions we end up with an output $D_F \\times D_F \\times 1$ in shape. Now stacking these outputs together we have an output volume of $G$ which is of shape $D_F \\times D_F \\times M$\nDepthwise convolution is extremely efficient relative to standard convolution. However it only filters input channels, it does not combine them to create new features. So an additional layer that computes a linear combination of the output of depthwise convolution via 1 x 1 convolution is needed in order to generate these new features.\nPointwise convolution Pointwise convolution involves performing the linear combination of each of these layers. Here the input is the volume of shape $D_F \\times D_F \\times M$, the filter has a shape of $1 \\times 1 \\times M$. This is basically a 1 x 1 convolution operation over all $M$ layers. The output this have the same input width and height as the input $D_F \\times D_F$ for each filter. Assuming that we want to use some $N$ such filters, the output volume becomes $D_F \\times D_F \\times N$.\nNow let\u0026rsquo;s take a look at the complexity of this convolution. We can split this into two parts as we have two phases. First we compute the number of multiplications in depthwise convolution. So here the kernels have a shape of $D_K \\times D_K \\times 1$ so the number of multiplications on one convolution operation is $D_K \\times D_K$. When applied over the entire input channel this convolution is performed $D_F \\times D_F$ number of times. So the total multiplications for the kernel over the input channels becomes $D_F \\times D_F \\times D_K \\times D_K$. Now such multiplications are applies over all $M$ input channels. For each input channel we have a difference kernel and hence the total number of multiplications in the first phase that is depthwise convolution is $D_F \\times D_F \\times D_K \\times D_K \\times M$. Next we compute the number of multiplications in the second phase that is pointwise convolution. Here the kernels have a shape of $1 \\times 1 \\times M$ where M is the depth of the input volume. Hence the number of multiplications for one instance of convolution is $M$. This is applied to the entire output of the first phase which has a width and height of $D_F$ so the total number of multiplications for this kernel is $D_F \\times D_F \\times M$. So for some $N$ kernels we will have $N \\times D_F \\times D_F \\times M$ such multiplications and thus the total number of multiplications in the depthwise convolution stage plus the number of multiplications in the pointwise convolution stage.\nHow exactly is this better? Depthwise separable convolutions cost: $$ D_F \\cdot D_F \\cdot D_K \\cdot D_K \\cdot M + M \\cdot N \\cdot D_F \\cdot D_F $$ By expressing convolution as a two step process of filtering and combining we get a reduction in computation of: $$ \\frac{D_F \\cdot D_F \\cdot D_K \\cdot D_K \\cdot M + M \\cdot N \\cdot D_F \\cdot D_F}{D_K \\cdot D_K \\cdot D_F \\cdot D_F \\cdot M \\cdot N} \\newline = \\frac{D_K \\cdot D_K + M}{D_K \\cdot D_K \\cdot N} \\newline = \\frac{1}{N} + \\frac{1}{D^2_K} $$\nTo put this into perspective of how effective depthwise separable convolution is let us take an example. Consider the output features volume $N$ of 1024 and a kernel size 3, that is $D_K$ is equal to 3. Plugging these values into the relation we get 0.112. In other words depthwise separable convolution uses 8 to 9 times less computation than standard convolution.\n","permalink":"https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/","summary":"Convolution is one of the fundamental building block of Deep Neural Network (DNN) but sometimes, it can be extremely expensive to compute since it brings a lots of parameters and we are running risk of overfiting. This is where depthwise separable convolution can be used to reduce the total number of parameters, as a result, speed up convolution. This is a form of factorized convolutions which factorize a standard convolution into a depthwise convolution and a 1 x 1 convolution called a pointwise convolution.","title":"Depthwise Separable Convolution - How does it works?"},{"content":"Linear Regression is the most basic, well known and well understood supervised learning algorithm. It\u0026rsquo;s probably the first thing that every Machine Learning Engineer and Data Scientist come across as it lays the foundation for other sophisticated learning algorithm. But what is it?\nWhat is Linear Regression? Before knowing what is linear regression, let us get ourselves accustomed to regression. Regression is a method of modeling the relationships between a dependent variable and one or more independent variables.\nIt is used when we want to predict the value of a variable based on the value of other variables. The variable we want to predict is called the dependent variable (also called the target or output). The variables we are using to predict the another variable\u0026rsquo;s value are called the independent variables (also called the features or input). Regression techniques mostly differ based on the number of independent variables and the type of relationship between the dependent and independent variables.\nLinear regression is a linear model, i.e. a model that assumes a linear relationship between the input variables $x$ and the single output variable $y$. More specifically, that $y$ can be calculated from a linear combination of the input variables. When there is a single input variable, the method is referred to as simple linear regression. When there are multiple input variables, literature from statistics often refers to the method as multiple linear regression.\nIn machine learning, linear regression is a supervised learning algorithm where the predicted output is continuous and has a constant slope. It’s used to for forecasting and finding out cause and effect relationship between variables within a continuous range (e.g. sales, price).\n Linear Regression In Real Life - by Carolina Bento   Linear Regression Model Representation Linear regression model is an attractive model because the representation is so simple. It\u0026rsquo;s just a function of one or more input feature $x$ and an output value $y$. As such, both the input and output value are numeric.\nMore generally, a linear model make prediction by simply computing a weighted sum of the input values plus a constant called the bias term (also called the intercept term), as shown in the equation below:\n$$y = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \u0026hellip; + \\theta_n x_n$$\nIn this equation:\n $y$ is the predicted value. $n$ is the number of features. $x_i$ is the $i^{th}$ feature value. $\\theta_j$ (pronounced theta) is the $j^{th}$ model parameter (including the bias term $\\theta_0$ and the feature weights $\\theta_1$, $\\theta_2$, \u0026hellip;, $\\theta_n$).  This can be written more concisely using a vectorized form as:\n$$y = h_{\\bm\\theta}\\left(\\textbf{x}\\right) = \\bm\\theta^T\\cdot\\textbf{x}$$\nWhere:\n $\\bm\\theta^T$ is the transpose of the model\u0026rsquo;s parameter vector, containing the bias term $\\theta_0$ and the feature weights $\\theta_1$ to $\\theta_n$. $\\textbf{x}$ is the instance\u0026rsquo;s feature vector, containing $x_0$ to $x_n$, with $x_0$ always equal to 1. $\\bm\\theta^T \\cdot \\textbf{x} $ is the dot product of the vectors $\\bm\\theta^T$ and $\\textbf{x}$. $h_{\\bm\\theta}$ is the hypothesis function, using the model parameters $\\theta$.  Our job is to set its parameters (i.e. find $\\bm\\theta$) so that the model best fits the training set. For this purpose we need some metric to measure how well (or poorly) the model fits the training data.\nThe Cost Function Mean Squared Error The most common performance measure of a regression model is the Root Mean Squared Error (RMSE). But in some contexts you may prefer to use another function, e.g. Mean Absolute Error (MAE) if there are many outliers. Here we\u0026rsquo;ll use the Mean Squared Error (MSE) because it is simplier to minimize than the RMSE, and it lead to the same result (because it value that minimizes this function also minimizes its square root).\nThe MSE of a Linear Regression hypothesis $h_{\\bm\\theta}$ on a training set $\\textbf{X}$ (also called the cost function) is calculated using the equation:\n$$ \\text{MSE}\\left(\\textbf{X}, h_{\\bm\\theta}\\right) = \\frac{1}{m} \\displaystyle\\sum_{i=1}^m \\left(\\bm\\theta^T \\textbf x^{(i)} - y^{(i)}\\right)^2 $$\nWhere:\n $m$ is the number of instances in the dataset you are measuring on. $\\bm\\theta^T \\textbf x^{(i)}$ is the predicted value of the model for the $i^{th}$ instance. $y^{(i)}$ is the target value of the $i^{th}$ instance. $\\textbf x^{(i)}$ is a vector of all the feature values $\\textbf{X}$ is a matrix containing all the feature values of all instances in the dataset. There is one instance per row, and the $i^{th}$ row is equal to the transpose of all the features of this instance $\\textbf{x}^{(i)}$ $h_{\\bm\\theta}$ is the model\u0026rsquo;s prediction function parameterized by the vector $\\theta$, also called the hypothesis.  What it does is calculate the difference between the model\u0026rsquo;s prediction and the true target value and square it (hence $\\left(\\bm\\theta^T \\textbf x^{(i)} - y^{(i)}\\right)^2$). Do it for all of the instances in the dataset then take the sum of all the calculated square differences. Divide that sum by the total number of instances in the dataset to get the mean. The larger the error, the larger the MSE and the opposite. We want to find the value of $\\bm\\theta$ to minimize the MSE.\nThe Normal Equation To find the value of $\\bm\\theta$ that minimizes the cost function, there is a closed-form solution - in other words, a mathematical equation that gives the result directly.\nLet us representing the cost function in a vector form, starting with the residual\n$$ \\begin{bmatrix} \\theta^T({x}^0)\\newline \\theta^T({x}^1)\\newline \\vdots \\newline \\theta^T({x}^m)\\newline \\end{bmatrix} - \\begin{bmatrix} y^0\\newline y^1\\newline \\vdots \\newline y^m\\newline \\end{bmatrix} = \\textbf{X} \\bm\\theta - y $$\nBut each residual value is squared. We can not simply square the above expression. As the square of a vector/matix is not equal to the square of each of its values. So to get the squared value, multiply the vector/matrix with its transpose. Therefore the final equation is:\n$$ \\text{MSE}\\left(\\textbf{X}, h_{\\bm\\theta}\\right) = \\frac{1}{m}\\left(\\left(\\textbf{X} \\bm\\theta - y\\right)^T \\left(\\textbf{X} \\bm\\theta - y\\right)\\right) \\newline = \\frac{1}{m}\\left(\\left(\\textbf{X}\\bm\\theta\\right)^T\\textbf{X}\\bm\\theta - y\\left(\\textbf{X}\\bm\\theta\\right)^T - y^T\\textbf{X}\\bm\\theta + y^Ty\\right) \\newline = \\frac{1}{m}\\left(\\bm\\theta^T \\textbf{X}^T \\textbf{X} \\bm\\theta - 2 \\bm\\theta^T \\textbf{X}^T y + y^Ty\\right) $$\nNow to minimize $\\text{MSE}\\left(\\textbf{X}, h_{\\bm\\theta}\\right)$ w.r.t. $\\theta$ we\u0026rsquo;ll set its derivative equal to 0 (i.e., implying that we have a local optimum of the error, it would be the best fit line for the dataset) and solve for $\\theta$. But how do we differentiate this?\nOk, here are the two useful identities we\u0026rsquo;ll need:\n Derivative of a linear function:  $$ \\frac{\\partial}{\\partial\\vec{x}}\\vec{a} \\cdot \\vec{x} = \\frac{\\partial}{\\partial\\vec{x}}\\vec{a}^T \\vec{x} = \\frac{\\partial}{\\partial\\vec{x}}\\vec{x}^T \\vec{a} = \\vec{a} $$\n(If you think back to calculus, this is just $\\frac{d}{dx}ax = a$)\n Derivative of a quadratic function: if A is symmetric, then:  $$ \\frac{\\partial}{\\partial\\vec{x}} \\vec{x}^T A \\vec{x} = 2 A \\vec{x} $$\n(Again, thinking back to calculus, this is just like $\\frac{d}{dx}ax^2 = 2ax$)\nIn case you\u0026rsquo;re wondering what if A is non-symmetric. The more general rule is:\n$$ \\frac{\\partial}{\\partial\\vec{x}} \\vec{x}^T A \\vec{x} = \\left(A + A^T\\right) \\vec{x} $$\nWhich of course is the same thing as $2A\\vec{x}$ when $A$ is symmetric.\nNow back at the cost function, we can see that it\u0026rsquo;s derivative w.r.t. $\\bm\\theta$ noted as $\\nabla_\\theta MSE(\\bm\\theta)$ (also called the gradient vector) is just:\n$$ \\nabla_\\theta MSE(\\bm\\theta) = \\frac{2}{m} \\left(\\textbf{X}^T\\textbf{X}\\bm\\theta - \\textbf{X}^Ty\\right) $$\nLet\u0026rsquo;s set it equal to 0 (noted as $\\stackrel{!}{=}$, think of it as \u0026ldquo;shall be (made) equal to\u0026rdquo;) and solve for $\\bm\\theta$\n$$ \\nabla_\\theta MSE(\\bm\\theta) = \\frac{2}{m} \\left(\\textbf{X}^T\\textbf{X}\\bm\\theta - \\textbf{X}^Ty\\right) \\stackrel{!}{=} 0 \\newline \\implies \\textbf{X}^T\\textbf{X}\\bm\\theta = \\textbf{X}^Ty \\newline \\implies \\bm\\theta = (\\textbf{X}^T \\textbf{X})^{-1} \\ \\ \\textbf{X}^T \\ \\ y $$\nThis is called the Normal Equation:\n$$ \\widehat{\\bm\\theta} = (\\textbf X^T \\textbf X )^{-1} \\ \\ \\textbf X^T \\ \\ y $$\nIn this equation:\n $\\widehat{\\bm\\theta}$ is the value of $\\bm\\theta$ that minimizes the cost function. $y$ is the vector of target values containing $y^{(1)}$ to $y^{(m)}$  Let\u0026rsquo;s generate some random linear-looking data to this equation.\nimport numpy as np X = 2 * np.random.rand(100, 1) y = 5 + 4 * X + np.random.randn(100, 1) Now let compute $\\widehat{\\bm\\theta}$ using the Normal Equation. We\u0026rsquo;ll use the np.linalg.inv() function from NumPy\u0026rsquo;s linear algebra module to compute the inverse of a matrix. Note that the @ symbol was introduced in Python 3.5 as matrix multiplication.\nX_b = np.c_[np.ones((100,1)), X] theta_bestfit = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y The function we used to generate the data is $y = 5 + 4x_1$ with some Gaussian noise. Let\u0026rsquo;s see what the equation found!\n\u0026gt;\u0026gt;\u0026gt; theta_bestfit array([[5.09647054], [4.01624421]]) Close enough. The noise made it impossible to recover the exact parameters of the original function. Now we can make prediction using $\\widehat{\\bm\\theta}$\nX_test = np.array([[0], [3]]) X_test_b = np.c_[np.ones((2,1)), X_test] y_predict = X_test_b @ theta_bestfit \u0026gt;\u0026gt;\u0026gt; y_predict array([[ 5.09647054], [17.14520317]]) But the Normal Equation may not work if the matrix $\\bm{X}^T\\bm{X}$ is not invertible (i.e. singular also called degenerate). This equation has a single solution if $\\bm{X}^T\\bm{X}$ is invertible (i.e. non-singular). If it\u0026rsquo;s not, you have more solutions.\nTake $\\textbf{X} = \\begin{bmatrix} 1 \u0026amp; 0 \\newline 0 \u0026amp; 1 \\newline 0 \u0026amp; 0 \\end{bmatrix}$ for example, it\u0026rsquo;s transpose will be $\\textbf{X}^T = \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 1 \u0026amp; 0 \\end{bmatrix} $. Therefore\n$$ \\textbf{X}^T \\textbf{X} = \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 1 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix} $$\nWe can see that the determinant of this matrix 0 so it is not invertible. Then how can we solve for $\\bm\\theta$? Use the Moore-Penrose inverse!\nThe Moore-Penrose Pseudoinverse In Linear Algebra, the Moore-Penrose inverse of a matrix is the most well known generalization of the inverse matrix. The term generalized inverse is sometimes used as a synonym for pseudoinverse. A common use of the pseudoinverse is to compute a \u0026ldquo;best fit\u0026rdquo; (least square) solution to a system of linear equations that lacks a solution. Another is to find the minimum (Euclidean) norm solution to a system of linear equations with multiple solutions. That\u0026rsquo;s exactly what we need.\nThe pseudoinverse itself is computed using a standard matrix factorization technique called Singular Value Decomposition (SVD) that can decompose any matrix $\\textbf X$ into the matrix multiplication of three matrices.\n$$ \\textbf{X} = \\textbf{U} \\Sigma \\textbf{V}^T $$\nWhere $\\textbf{U}$ and $\\textbf{V}$ are orthogonal matrices (i.e. its inverse equal to its transpose), $\\Sigma$ is a diagonal matrix (i.e. entries out side the main diagonal are zeros).\nWhat does it actually do? You might ask. I\u0026rsquo;ll save it for another post. It\u0026rsquo;s deserve a post of its own. Now let\u0026rsquo;s suppose $\\textbf X$ is invertible, then its inverse is\n$$ \\textbf X^{-1} = \\textbf V \\Sigma^{-1} \\textbf U^T $$\nThe pseudoinverse of $\\textbf{X}$ is quite similar but instead of $\\Sigma^{-1}$ we use it\u0026rsquo;s pseudoinverse $\\Sigma^+$\n$$ \\textbf{X}^+ = \\textbf{V} \\Sigma^+ \\textbf{U}^T $$\nWhere $\\Sigma^+$ is computed by replace all nonzero values with their inverse and transpose the resulting matrix.\nNow let\u0026rsquo;s take our linear model equation above and rewrite it in its matrix form as:\n$$ \\textbf{X} \\bm\\theta = y $$\nWe know that inverse of a matrix multiply by itself is equal to the identity matrix and any matrix multiply by the identity matrix result in the matrix itself. Hence\n$$ \\textbf{X}^+ \\textbf{X} \\bm\\theta = \\textbf{X}^+ y \\newline \\implies \\bm\\theta = \\textbf{X}^+ y $$\nSee something similar? That\u0026rsquo;s right, it looks like our Normal Equation above. It implies that\n$$ \\textbf{X}^+ = \\textbf{V} \\Sigma^+ \\textbf{U}^T = (\\textbf X^T \\textbf X )^{-1} \\ \\ \\textbf X^T $$\nIndeed, if we multiply the left and right side of the equation to $\\textbf{X}$ we\u0026rsquo;ll get back the identity matrix\n$$ \\textbf{X}^+ \\textbf{X} = (\\textbf X^T \\textbf X)^{-1} \\ \\ \\textbf X^T \\textbf{X} = \\textbf I $$\nOr if we take the right hand side of the equation, plug in the SVD and cancel like crazy we\u0026rsquo;ll get\n$$ (\\textbf X^T \\textbf X)^{-1} \\ \\ \\textbf X^T \\newline = (\\textbf U^T \\Sigma \\textbf V \\ \\textbf U \\Sigma \\textbf V^T)^{-1} \\ \\textbf U^T \\Sigma \\textbf V \\newline = \\textbf V \\Sigma^+ \\textbf U^T \\ \\textbf V^T \\Sigma^+ \\textbf U \\ \\textbf U^T \\Sigma \\textbf V \\newline = \\textbf V \\Sigma^+ \\textbf U^T $$\nThis approach is more efficient than computing the Normal Equation, plus it handles edge cases nicely and the pseudoinverse is always defined.\nPerforming Moore-Penrose Pseudoinverse in python is simple. Just call np.linalg.pinv() instead!\ntheta_pinv = np.linalg.pinv(X_b) @ y \u0026gt;\u0026gt;\u0026gt; theta_pinv array([[5.09647054], [4.01624421]]) Computational Complexity The Normal Equation computes the inverse of $\\textbf{X}^T \\textbf X$, which is an $(n + 1) \\times (n + 1)$ matrix (where $n$ is the number of features). The computational complexity of inverting such an matrix is typically about $O(n^{2.4})$ to $O(n^3)$, depending on the implementation. In other words, if you double the number of features, you multiply the computational time by roughly $2^{2.4} = 5.3$ to $2^3 = 8$.\nThe SVD approach used by Scikit-Learn\u0026rsquo;s LinearRegression class is about $O(n^2)$. If you double the number of features, you multiply the computational time by roughly 4.\nWhat it means is both the Normal Equation and the SVD approach get very slow when the number of features grows large (e.g. 100,000). On the positive side, both are linear with regard to the number of instances in the training set (they are $O(m)$), so they handle large training sets efficiently, provided they can fit in memory.\nAlso, once you have trained your Linear Regression model (using the Normal Equation or any other algorithm), predictions are very fast: the computational complexity is linear with regard to both the number of instances you want to make predictions on and the number of features. In other words, making predictions on twice as many instances (or twice as many features) will take roughly twice as much time.\nNow we\u0026rsquo;ll look at a very different way to train a Linear Regression model, which is better suited for cases where there are a large number of features or too many training instances to fit in memory.\nGradient Descent Gradient Descent is a generic optimization algorithm capable of finding optimal solutions to a wide range of problems. The general idea of Gradient Descent is to tweak parameters iteratively in order to minimize a cost function. It measures the local gradient of the error function with regard to the parameter vector $\\theta$, and it goes in the direction of descending gradient. Once the gradient is zero, you have reached a minimum!\nGenerally you start by defining $\\theta$ with random values (this is called random initialization). Then you improve it gradually, taking one baby step at a time, each step attempting to decrease the cost function (e.g. the MSE), until the algorithm converges to a minimum.\nAn important parameter in Gradient Descent is the size of the step, determined by the learning rate hyperparameter. If the learning rate is too small, then the algorithm will have to go through many iterations to converges, which will take a long time.\nOn the other hand, if the learning rate is too high, you might over shoot the local minimum, possibly even higher error than you were before. This might make the algorithm diverge, with larger and larger values, failing to find a good solution.\nFinally, not all cost functions looks like nice, regular bowls. There may be holes, ridges plateaus, and all sort of irregular terrains, making convergence to the minimum difficult.\nFortunately, the MSE cost function for a Linear Regression model happens to be a convex function, which means that if you pick any two points on the curve, the line segment join them never crosses the curve. This implies that there are no local minima, just one global minimum. It is also a continuous function with a slope that never changes abruptly. These two facts have a great consequence: Gradient Descent is guaranteed to approach arbitrary close the global minimum.\nTo implement Gradient Descent, you need to compute the gradient of the cost function with regard to each model parameter $\\theta_j$. In other words, you need to calculate how much the cost function will change if you change $\\theta_j$ just a little bit. This is called the partial derivative. It is like asking \u0026ldquo;If I take one small step ahead, which way is downhill?\u0026rdquo;. The equation to computes the partial derivative of the cost function with regard to parameter $\\theta_j$ noted $\\frac{\\partial}{\\partial\\theta_j}MSE(\\bm\\theta)$ is\n$$ \\frac{\\partial}{\\partial\\theta_j}MSE(\\bm\\theta)\\ = \\frac{2}{m} \\sum_{i=1}^m (\\bm\\theta^T \\textbf{x}^{(i)} - y^{(i)})x_j^{(i)} $$\nInstead of computing these partial derivatives individually, you can use the equation below (just like we\u0026rsquo;ve worked it out above for the Normal Equation) to compute them all in one go. The gradient vector, noted $\\nabla_\\theta MSE(\\bm\\theta)$, contains all the partial derivatives of the cost function (one for each model parameter).\n$$ \\nabla_\\theta MSE(\\bm\\theta) = \\begin{pmatrix} \\frac{\\partial}{\\partial\\theta_0}MSE(\\bm\\theta) \\newline \\frac{\\partial}{\\partial\\theta_1}MSE(\\bm\\theta) \\newline \\vdots \\newline \\frac{\\partial}{\\partial\\theta_n}MSE(\\bm\\theta) \\newline \\end{pmatrix} = \\frac{2}{m} \\textbf X^T (\\textbf X \\bm\\theta - \\bm y) $$\nNotice that this formula involves calculations over the full training set $\\textbf X$, at each Gradient Descent step! As a result it is terribly slow on very large training sets. However, Gradient Descent scales well with the number of features; training a Linear Regression model when there are hundreds of thousands of features is much fast using Gradient Descent than using the Normal Equation or SVD decomposition.\nOnce you have the gradient vector, which increase the MSE, just go in the opposite direction. That means subtracting $\\nabla_{\\bm\\theta} MSE(\\bm\\theta)$ from $\\bm\\theta$. This is where the learning rate $\\eta$ comes in to plays: multiply the gradient vector by $\\eta$ to determine the size of the downhill step.\n$$ \\bm\\theta^{\\text{(next step)}} = \\bm\\theta - \\eta \\nabla_{\\bm\\theta} MSE(\\bm\\theta) $$\nLet\u0026rsquo;s look at a quick implementation of this algorithm.\neta = 0.1 n_iteration = 1000 m = 100 theta = np.random.randn(2, 1) for iteration in range(n_iteration): gradients = 2/m * X_b.T @ (X_b @ theta - y) theta -= eta * gradients That wasn\u0026rsquo;t too hard! Let\u0026rsquo;s take a look at the resulting $\\bm\\theta$\n\u0026gt;\u0026gt;\u0026gt; theta array([[5.09647054], [4.01624421]]) That\u0026rsquo;s exactly what the Normal Equation found! But what if you have used a different learning rates $\\eta$?\nOn the left the learning rate is too low: the algorithm will eventually reach the solution, but it will take a long time. On the right the learning rate is too high: the algorithm diverges, jumping all over the place and actually getting further and further away from the solution at every step. In the middle, the learning rate looks pretty good: in just a few iterations, it has already converged to the solution.\nConclution Linear Regression is an algorithm that every Data Scientist and Machine Learning engineer must know. It is also a good place to start for people who want to get into the Machine Learning industry as well. It is really a simple but useful algorithm.\nIn this post we have learnt about the concepts of linear regression and gradient descent. We also had a deep dive into the mathematics behind it as well as implemented the model from scratch using only NumPy. I hope you had as much fun reading as I did writing it.\nThank you for reading!\n","permalink":"https://nguyentritai.tk/posts/2020/linear-regression/","summary":"Linear Regression is the most basic, well known and well understood supervised learning algorithm. It\u0026rsquo;s probably the first thing that every Machine Learning Engineer and Data Scientist come across as it lays the foundation for other sophisticated learning algorithm. But what is it?\nWhat is Linear Regression? Before knowing what is linear regression, let us get ourselves accustomed to regression. Regression is a method of modeling the relationships between a dependent variable and one or more independent variables.","title":"Linear Regression and a deep dive into the mathematics behind it."},{"content":" Nguyen Tri Tai   A Junior AI R\u0026D Engineer based in Ho Chi Minh, Viet Nam.  Specializing in Computer Vision including Image Recognition, Segmentation and Generation.  Also a book lover, photographer and guitar player.  ","permalink":"https://nguyentritai.tk/about/","summary":" Nguyen Tri Tai   A Junior AI R\u0026D Engineer based in Ho Chi Minh, Viet Nam.  Specializing in Computer Vision including Image Recognition, Segmentation and Generation.  Also a book lover, photographer and guitar player.  ","title":""}]