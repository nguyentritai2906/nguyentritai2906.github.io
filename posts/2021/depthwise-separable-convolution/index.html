<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Depthwise Separable Convolution - How does it works? | nttai</title>
<meta name="keywords" content="Machine Learning" />
<meta name="description" content="Convolution is one of the fundamental building block of Deep Neural Network (DNN) but sometimes, it can be extremely expensive to compute since it brings a lots of parameters and we are running risk of overfiting. This is where depthwise separable convolution can be used to reduce the total number of parameters, as a result, speed up convolution. This is a form of factorized convolutions which factorize a standard convolution into a depthwise convolution and a 1 x 1 convolution called a pointwise convolution.">
<meta name="author" content="Nguyen Tri Tai">
<link rel="canonical" href="https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.258309a8cbd70e6f8f22e7e835f7cf1dbd70d1c793875353813389b8419684d9.css" integrity="sha256-JYMJqMvXDm&#43;PIufoNffPHb1w0ceTh1NTgTOJuEGWhNk=" rel="preload stylesheet" as="style">
<link rel="preload" href="/avatar.png" as="image">
<link rel="icon" href="https://nguyentritai.tk/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://nguyentritai.tk/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://nguyentritai.tk/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://nguyentritai.tk/apple-touch-icon.png">
<link rel="mask-icon" href="https://nguyentritai.tk/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.92.0" />
<link rel="alternate" hreflang="en" href="https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/" />

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" integrity="sha384-Xi8rHCmBmhbuyyhbI88391ZKP2dmfnOl4rT9ZfRI7mLTdk1wblIUnrIq35nqwEvC" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js" integrity="sha384-X/XCfMm41VSsqRNQgDerQczD69XqmjOOOwYQvr/uuC+j4OPoNhVgjdGFwhvN02Ja" crossorigin="anonymous"></script>


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                    
                    
                    delimiters: [
                            {left: '$$', right: '$$', display: true},
                            {left: '$', right: '$', display: false},
                            {left: '\\(', right: '\\)', display: false},
                            {left: '\\[', right: '\\]', display: true}
                        ],
                    
                    throwOnError : false
                });
        });
</script>
<script>
  window.WebFontConfig = {
    custom: {
      families: ['KaTeX_AMS', 'KaTeX_Caligraphic:n4,n7', 'KaTeX_Fraktur:n4,n7',
        'KaTeX_Main:n4,n7,i4,i7', 'KaTeX_Math:i4,i7', 'KaTeX_Script',
        'KaTeX_SansSerif:n4,n7,i4', 'KaTeX_Size1', 'KaTeX_Size2', 'KaTeX_Size3',
        'KaTeX_Size4', 'KaTeX_Typewriter'],
    },
  };
</script>
<script defer src="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.js" integrity="sha256-4O4pS1SH31ZqrSO2A/2QJTVjTPqVe+jnYgOWUVr7EEc=" crossorigin="anonymous"></script>


<meta property="og:title" content="Depthwise Separable Convolution - How does it works?" />
<meta property="og:description" content="Convolution is one of the fundamental building block of Deep Neural Network (DNN) but sometimes, it can be extremely expensive to compute since it brings a lots of parameters and we are running risk of overfiting. This is where depthwise separable convolution can be used to reduce the total number of parameters, as a result, speed up convolution. This is a form of factorized convolutions which factorize a standard convolution into a depthwise convolution and a 1 x 1 convolution called a pointwise convolution." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/" />
<meta property="og:image" content="https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/cover.png" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-08-22T16:01:28&#43;07:00" />
<meta property="article:modified_time" content="2021-08-22T16:01:28&#43;07:00" /><meta property="og:site_name" content="nttai" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/cover.png" />
<meta name="twitter:title" content="Depthwise Separable Convolution - How does it works?"/>
<meta name="twitter:description" content="Convolution is one of the fundamental building block of Deep Neural Network (DNN) but sometimes, it can be extremely expensive to compute since it brings a lots of parameters and we are running risk of overfiting. This is where depthwise separable convolution can be used to reduce the total number of parameters, as a result, speed up convolution. This is a form of factorized convolutions which factorize a standard convolution into a depthwise convolution and a 1 x 1 convolution called a pointwise convolution."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://nguyentritai.tk/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Depthwise Separable Convolution - How does it works?",
      "item": "https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Depthwise Separable Convolution - How does it works?",
  "name": "Depthwise Separable Convolution - How does it works?",
  "description": "Convolution is one of the fundamental building block of Deep Neural Network (DNN) but sometimes, it can be extremely expensive to compute since it brings a lots of parameters and we are running risk of overfiting. This is where depthwise separable convolution can be used to reduce the total number of parameters, as a result, speed up convolution. This is a form of factorized convolutions which factorize a standard convolution into a depthwise convolution and a 1 x 1 convolution called a pointwise convolution.",
  "keywords": [
    "Machine Learning"
  ],
  "articleBody": "Convolution is one of the fundamental building block of Deep Neural Network (DNN) but sometimes, it can be extremely expensive to compute since it brings a lots of parameters and we are running risk of overfiting. This is where depthwise separable convolution can be used to reduce the total number of parameters, as a result, speed up convolution. This is a form of factorized convolutions which factorize a standard convolution into a depthwise convolution and a 1 x 1 convolution called a pointwise convolution.\nWhat is Depthwise Separable Convolution? Depthwise separable convolution first use the depthwise convolution to applies a single filter to each input channel. Then the pointwise convolution is used to applies a 1 x 1 convolution to combine the outputs of the depthwise convolution. This differ from the standard convolution since it both filters and combines inputs into a new set of outputs in one step, thus more expensive in computation.\nThis depthwise separable convolution splits this into two layers, a separate layer for filtering and a separate layer for combining. This factorization has the effect of drastically reducing computation and model size.\nStandard convolution A standard convolution layer takes as input a $D_F \\times D_F \\times M$ feature map $F$ and produces a $D_F \\times D_F \\times N$ feature map $G$ where $D_F$ is the spatial width and height of a square input feature map (assume that the output feature map has the same spatial dimensions as the input and both feature maps are square), $M$ is the number of input channels (input depth), and $N$ is the number of output channel (output depth).\nThe standard convolutional layer is parameterized by convolution kernel $K$ of size $D_K \\times D_K \\times M \\times N$ where $D_K$ is the spatial dimension of the kernel assumed to be square and $M$ is the number of input channels and $N$ is the number of output channels.\nThe output feature map for standard convolution assuming stride of one and padding is computed as: $$ G_{k,l,n} = \\sum_{i,j,n} K_{i,j,m,n} \\cdot F_{k+i-1,l+j-1,m} $$\nstandard convolutions have the computational cost of: $$ D_K \\cdot D_K \\cdot D_F \\cdot D_F \\cdot M \\cdot N $$\nThat is, for one convolution operation, the number of multiplications is the number of elements in that kernel so that would be $D_K \\times D_K \\times M$ multiplications. But we slide this kernel over the input, we perform $D_K$ convolutions along the width and $D_K$ convolutions along the height and hence $D_K \\times D_K$ convolutions over all. So the number of multiplications in the convolution of one kernel over the entire input $F$ is: $$ D_K \\cdot D_K \\cdot D_F \\cdot D_F \\cdot M $$ Now this is just one kernel but if we have $N$ such kernels which makes the absolute total number of multiplications become: $$ D_K \\cdot D_K \\cdot D_F \\cdot D_F \\cdot M \\cdot N $$\nDepthwise convolution The standard convolution operation has the effect of filtering features based on the convolutional kernels and combining features in order to produce a new representation. The filtering and combination steps can be split into two steps via the use of factorized convolutions called depthwise separable convolutions for substantial reduction in computational cost.\nDepthwise separable convolution are made up of two layers: depthwise convolution and pointwise convolutions. The depthwise convolution to apply a single filter per each input channel (input depth). Pointwise convolution, a simple 1 x 1 convolution, is then used to create a linear combination of the output of the depthwise layer.\nFirst it uses depthwise convolutions to break the interaction between the number of output channels and the size of the kernel. Depthwise convolution with one filter per input channel (input depth) can be written as: $$ \\hat G_{k,l,m} = \\sum_{i,j} \\hat K_{i,j,m} \\cdot F_{k+i-1,l+j-1,m} $$\nWhere $\\hat{K}$ is the depthwise convolutional kernel of size $D_K \\times D_K \\times M$ where the $m^{th}$ filter in $\\hat{K}$ is applied to the $m^{th}$ channel in $F$ to produce the $m^{th}$ channel of the filtered output feature map $\\hat{G}$.\nDepthwise convolution has a computational cost of: $$ D_K \\cdot D_K \\cdot D_F \\cdot D_F \\cdot M $$\nFor depthwise convolution we use filters or kernels of shape $D_K \\times D_K \\times 1$ here it has a depth of one because this convolution is only applied to a channel, unlike standard convolution which is applied throughout the entire depth. Since we apply one kernel to a single input channel, we require $M$ such $D_K \\times D_K \\times 1$ over the entire input volume $F$ for each of these $M$ convolutions we end up with an output $D_F \\times D_F \\times 1$ in shape. Now stacking these outputs together we have an output volume of $G$ which is of shape $D_F \\times D_F \\times M$\nDepthwise convolution is extremely efficient relative to standard convolution. However it only filters input channels, it does not combine them to create new features. So an additional layer that computes a linear combination of the output of depthwise convolution via 1 x 1 convolution is needed in order to generate these new features.\nPointwise convolution Pointwise convolution involves performing the linear combination of each of these layers. Here the input is the volume of shape $D_F \\times D_F \\times M$, the filter has a shape of $1 \\times 1 \\times M$. This is basically a 1 x 1 convolution operation over all $M$ layers. The output this have the same input width and height as the input $D_F \\times D_F$ for each filter. Assuming that we want to use some $N$ such filters, the output volume becomes $D_F \\times D_F \\times N$.\nNow let’s take a look at the complexity of this convolution. We can split this into two parts as we have two phases. First we compute the number of multiplications in depthwise convolution. So here the kernels have a shape of $D_K \\times D_K \\times 1$ so the number of multiplications on one convolution operation is $D_K \\times D_K$. When applied over the entire input channel this convolution is performed $D_F \\times D_F$ number of times. So the total multiplications for the kernel over the input channels becomes $D_F \\times D_F \\times D_K \\times D_K$. Now such multiplications are applies over all $M$ input channels. For each input channel we have a difference kernel and hence the total number of multiplications in the first phase that is depthwise convolution is $D_F \\times D_F \\times D_K \\times D_K \\times M$. Next we compute the number of multiplications in the second phase that is pointwise convolution. Here the kernels have a shape of $1 \\times 1 \\times M$ where M is the depth of the input volume. Hence the number of multiplications for one instance of convolution is $M$. This is applied to the entire output of the first phase which has a width and height of $D_F$ so the total number of multiplications for this kernel is $D_F \\times D_F \\times M$. So for some $N$ kernels we will have $N \\times D_F \\times D_F \\times M$ such multiplications and thus the total number of multiplications in the depthwise convolution stage plus the number of multiplications in the pointwise convolution stage.\nHow exactly is this better? Depthwise separable convolutions cost: $$ D_F \\cdot D_F \\cdot D_K \\cdot D_K \\cdot M + M \\cdot N \\cdot D_F \\cdot D_F $$ By expressing convolution as a two step process of filtering and combining we get a reduction in computation of: $$ \\frac{D_F \\cdot D_F \\cdot D_K \\cdot D_K \\cdot M + M \\cdot N \\cdot D_F \\cdot D_F}{D_K \\cdot D_K \\cdot D_F \\cdot D_F \\cdot M \\cdot N} \\newline = \\frac{D_K \\cdot D_K + M}{D_K \\cdot D_K \\cdot N} \\newline = \\frac{1}{N} + \\frac{1}{D^2_K} $$\nTo put this into perspective of how effective depthwise separable convolution is let us take an example. Consider the output features volume $N$ of 1024 and a kernel size 3, that is $D_K$ is equal to 3. Plugging these values into the relation we get 0.112. In other words depthwise separable convolution uses 8 to 9 times less computation than standard convolution.\n",
  "wordCount" : "1350",
  "inLanguage": "en",
  "image":"https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/cover.png","datePublished": "2021-08-22T16:01:28+07:00",
  "dateModified": "2021-08-22T16:01:28+07:00",
  "author":{
    "@type": "Person",
    "name": "Nguyen Tri Tai"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "nttai",
    "logo": {
      "@type": "ImageObject",
      "url": "https://nguyentritai.tk/favicon.ico"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    }

</script>
<noscript>
    <style type="text/css">
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://nguyentritai.tk/" accesskey="h" title="nttai (Alt + H)">nttai</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="https://nguyentritai.tk/vi/" title="Vietnamese"
                            aria-label=":vi:">Vi</a>
                    </li>
                </ul>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://nguyentritai.tk/posts" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://nguyentritai.tk/archive" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://nguyentritai.tk/categories" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://nguyentritai.tk/tags" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://nguyentritai.tk/search" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://nguyentritai.tk/about" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
    <header class="post-header">
        <div class="breadcrumbs"><a href="https://nguyentritai.tk/">Home</a>&nbsp;»&nbsp;<a href="https://nguyentritai.tk/posts/">Posts</a></div>
        <h1 class="post-title">
            Depthwise Separable Convolution - How does it works?
        </h1>
        <div class="post-meta">August 22, 2021&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Nguyen Tri Tai
</div>
    </header> 
<figure class="entry-cover">
        <img loading="lazy" srcset="https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/cover_hu999ffbb791a0d442e18a16c1fd8698ed_270188_360x0_resize_box_3.png 360w ,https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/cover_hu999ffbb791a0d442e18a16c1fd8698ed_270188_480x0_resize_box_3.png 480w ,https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/cover_hu999ffbb791a0d442e18a16c1fd8698ed_270188_720x0_resize_box_3.png 720w ,https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/cover_hu999ffbb791a0d442e18a16c1fd8698ed_270188_1080x0_resize_box_3.png 1080w ,https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/cover_hu999ffbb791a0d442e18a16c1fd8698ed_270188_1500x0_resize_box_3.png 1500w ,https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/cover.png 1920w"
            sizes="(min-width: 768px) 720px, 100vw" src="https://nguyentritai.tk/posts/2021/depthwise-separable-convolution/cover.png" alt="Depthwise separable convolution" />
        
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <div class="details">Table of Contents</div>
        </summary>
        <div class="inner"><ul>
                <li>
                    <a href="#what-is-depthwise-separable-convolution" aria-label="What is Depthwise Separable Convolution?">What is Depthwise Separable Convolution?</a><ul>
                        
                <li>
                    <a href="#standard-convolution" aria-label="Standard convolution">Standard convolution</a></li>
                <li>
                    <a href="#depthwise-convolution" aria-label="Depthwise convolution">Depthwise convolution</a></li>
                <li>
                    <a href="#pointwise-convolution" aria-label="Pointwise convolution">Pointwise convolution</a></li></ul>
                </li>
                <li>
                    <a href="#how-exactly-is-this-better" aria-label="How exactly is this better?">How exactly is this better?</a>
                </li>
            </ul>
        </div>
    </details>
</div>

    <div class="post-content"><p>Convolution is one of the fundamental building block of Deep Neural Network
(DNN) but sometimes, it can be extremely expensive to compute since it brings a
lots of parameters and we are running risk of overfiting. This is where
depthwise separable convolution can be used to reduce the total number of
parameters, as a result, speed up convolution. This is a form of factorized
convolutions which factorize a standard convolution into a depthwise convolution
and a 1 x 1 convolution called a pointwise convolution.</p>
<h1 id="what-is-depthwise-separable-convolution">What is Depthwise Separable Convolution?<a hidden class="anchor" aria-hidden="true" href="#what-is-depthwise-separable-convolution">#</a></h1>
<p>Depthwise separable convolution first use the depthwise convolution to applies a
single filter to each input channel. Then the pointwise convolution is used to
applies a 1 x 1 convolution to combine the outputs of the depthwise convolution.
This differ from the standard convolution since it both filters and combines
inputs into a new set of outputs in one step, thus more expensive in
computation.</p>
<p>This depthwise separable convolution splits this into two layers, a separate
layer for filtering and a separate layer for combining. This factorization has
the effect of drastically reducing computation and model size.</p>
<h2 id="standard-convolution">Standard convolution<a hidden class="anchor" aria-hidden="true" href="#standard-convolution">#</a></h2>
<p>A standard convolution layer takes as input a $D_F \times D_F \times M$ feature
map $F$ and produces a $D_F \times D_F \times N$ feature map $G$ where $D_F$ is
the spatial width and height of a square input feature map (assume that the
output feature map has the same spatial dimensions as the input and both feature
maps are square), $M$ is the number of input channels (input depth), and $N$ is
the number of output channel (output depth).</p>
<p>The standard convolutional layer is parameterized by convolution kernel $K$ of
size $D_K \times D_K \times M \times N$ where $D_K$ is the spatial dimension of
the kernel assumed to be square and $M$ is the number of input channels and $N$
is the number of output channels.</p>
<p>The output feature map for standard convolution assuming stride of one and
padding is computed as:
$$
G_{k,l,n} = \sum_{i,j,n} K_{i,j,m,n} \cdot F_{k+i-1,l+j-1,m}
$$</p>
<p>standard convolutions have the computational cost of:
$$
D_K \cdot D_K \cdot D_F \cdot D_F \cdot M \cdot N
$$</p>
<p>That is, for one convolution operation, the number of multiplications is the
number of elements in that kernel so that would be $D_K \times D_K \times M$
multiplications. But we slide this kernel over the input, we perform $D_K$
convolutions along the width and $D_K$ convolutions along the height and hence
$D_K \times D_K$ convolutions over all. So the number of multiplications in the
convolution of one kernel over the entire input $F$ is:
$$
D_K \cdot D_K \cdot D_F \cdot D_F \cdot M
$$
Now this is just one kernel but if we have $N$ such kernels which makes the
absolute total number of multiplications become:
$$
D_K \cdot D_K \cdot D_F \cdot D_F \cdot M \cdot N
$$</p>
<h2 id="depthwise-convolution">Depthwise convolution<a hidden class="anchor" aria-hidden="true" href="#depthwise-convolution">#</a></h2>
<p>The standard convolution operation has the effect of filtering features based on
the convolutional kernels and combining features in order to produce a new
representation. The filtering and combination steps can be split into two steps
via the use of factorized convolutions called depthwise separable convolutions
for substantial reduction in computational cost.</p>
<p>Depthwise separable convolution are made up of two layers: depthwise convolution
and pointwise convolutions. The depthwise convolution to apply a single filter
per each input channel (input depth). Pointwise convolution, a simple 1 x 1
convolution, is then used to create a linear combination of the output of the
depthwise layer.</p>
<p>First it uses depthwise convolutions to break the interaction between the number
of output channels and the size of the kernel. Depthwise convolution with one
filter per input channel (input depth) can be written as:
$$
\hat G_{k,l,m} = \sum_{i,j} \hat K_{i,j,m} \cdot F_{k+i-1,l+j-1,m}
$$</p>
<p>Where $\hat{K}$ is the depthwise convolutional kernel of size $D_K \times D_K
\times M$ where the $m^{th}$ filter in $\hat{K}$ is applied to the $m^{th}$
channel in $F$ to produce the $m^{th}$ channel of the filtered output feature
map $\hat{G}$.</p>
<p>Depthwise convolution has a computational cost of:
$$
D_K \cdot D_K \cdot D_F \cdot D_F \cdot M
$$</p>
<p>For depthwise convolution we use filters or kernels of shape $D_K \times D_K
\times 1$ here it has a depth of one because this convolution is only applied to
a channel, unlike standard convolution which is applied throughout the entire
depth. Since we apply one kernel to a single input channel, we require $M$ such
$D_K \times D_K \times 1$ over the entire input volume $F$ for each of these $M$
convolutions we end up with an output $D_F \times D_F \times 1$ in shape. Now
stacking these outputs together we have an output volume of $G$ which is of
shape $D_F \times D_F \times M$</p>
<p>Depthwise convolution is extremely efficient relative to standard convolution.
However it only filters input channels, it does not combine them to create new
features. So an additional layer that computes a linear combination of the
output of depthwise convolution via 1 x 1 convolution is needed in order to
generate these new features.</p>
<h2 id="pointwise-convolution">Pointwise convolution<a hidden class="anchor" aria-hidden="true" href="#pointwise-convolution">#</a></h2>
<p>Pointwise convolution involves performing the linear combination of each of
these layers. Here the input is the volume of shape $D_F \times D_F \times M$,
the filter has a shape of $1 \times 1 \times M$. This is basically a 1 x 1
convolution operation over all $M$ layers. The output this have the same input
width and height as the input $D_F \times D_F$ for each filter. Assuming that we
want to use some $N$ such filters, the output volume becomes $D_F \times D_F
\times N$.</p>
<p>Now let&rsquo;s take a look at the complexity of this convolution. We can split this
into two parts as we have two phases. First we compute the number of
multiplications in depthwise convolution. So here the kernels have a shape of
$D_K \times D_K \times 1$ so the number of multiplications on one convolution
operation is $D_K \times D_K$. When applied over the entire input channel this
convolution is performed $D_F \times D_F$ number of times. So the total
multiplications for the kernel over the input channels becomes $D_F \times D_F
\times D_K \times D_K$. Now such multiplications are applies over all $M$ input
channels. For each input channel we have a difference kernel and hence the total
number of multiplications in the first phase that is depthwise convolution is
$D_F \times D_F \times D_K \times D_K \times M$. Next we compute the number of
multiplications in the second phase that is pointwise convolution. Here the
kernels have a shape of $1 \times 1 \times M$ where M is the depth of the input
volume. Hence the number of multiplications for one instance of convolution is
$M$. This is applied to the entire output of the first phase which has a width
and height of $D_F$ so the total number of multiplications for this kernel is
$D_F \times D_F \times M$. So for some $N$ kernels we will have $N \times D_F
\times D_F \times M$ such multiplications and thus the total number of
multiplications in the depthwise convolution stage plus the number of
multiplications in the pointwise convolution stage.</p>
<h1 id="how-exactly-is-this-better">How exactly is this better?<a hidden class="anchor" aria-hidden="true" href="#how-exactly-is-this-better">#</a></h1>
<p>Depthwise separable convolutions cost:
$$
D_F \cdot D_F \cdot D_K \cdot D_K \cdot M + M \cdot N \cdot D_F \cdot D_F
$$
By expressing convolution as a two step process of filtering and combining we
get a reduction in computation of:
$$
\frac{D_F \cdot D_F \cdot D_K \cdot D_K \cdot M + M \cdot N \cdot D_F \cdot D_F}{D_K \cdot D_K \cdot D_F \cdot D_F \cdot M \cdot N}
\newline = \frac{D_K \cdot D_K + M}{D_K \cdot D_K \cdot N}
\newline = \frac{1}{N} + \frac{1}{D^2_K}
$$</p>
<p>To put this into perspective of how effective depthwise separable convolution is
let us take an example. Consider the output features volume $N$ of 1024 and a
kernel size 3, that is $D_K$ is equal to 3. Plugging these values into the
relation we get 0.112. In other words depthwise separable convolution uses 8 to
9 times less computation than standard convolution.</p>

</div>
    <footer class="post-footer">
        <ul class="post-tags">
            <li><a href="https://nguyentritai.tk/tags/machine-learning/">Machine Learning</a></li>
        </ul>
<nav class="paginav">
  <a class="prev" href="https://nguyentritai.tk/posts/2022/tensorboard-projector-image-visualizer/">
    <span class="title">« Prev Page</span>
    <br>
    <span>Tensorboard Projector Image Visualizer with Tensorflow 2</span>
  </a>
  <a class="next" href="https://nguyentritai.tk/posts/2020/linear-regression/">
    <span class="title">Next Page »</span>
    <br>
    <span>Linear Regression and a deep dive into the mathematics behind it.</span>
  </a>
</nav>

<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Depthwise Separable Convolution - How does it works? on twitter"
        href="https://twitter.com/intent/tweet/?text=Depthwise%20Separable%20Convolution%20-%20How%20does%20it%20works%3f&amp;url=https%3a%2f%2fnguyentritai.tk%2fposts%2f2021%2fdepthwise-separable-convolution%2f&amp;hashtags=MachineLearning">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Depthwise Separable Convolution - How does it works? on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fnguyentritai.tk%2fposts%2f2021%2fdepthwise-separable-convolution%2f&amp;title=Depthwise%20Separable%20Convolution%20-%20How%20does%20it%20works%3f&amp;summary=Depthwise%20Separable%20Convolution%20-%20How%20does%20it%20works%3f&amp;source=https%3a%2f%2fnguyentritai.tk%2fposts%2f2021%2fdepthwise-separable-convolution%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Depthwise Separable Convolution - How does it works? on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fnguyentritai.tk%2fposts%2f2021%2fdepthwise-separable-convolution%2f&title=Depthwise%20Separable%20Convolution%20-%20How%20does%20it%20works%3f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Depthwise Separable Convolution - How does it works? on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fnguyentritai.tk%2fposts%2f2021%2fdepthwise-separable-convolution%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Depthwise Separable Convolution - How does it works? on whatsapp"
        href="https://api.whatsapp.com/send?text=Depthwise%20Separable%20Convolution%20-%20How%20does%20it%20works%3f%20-%20https%3a%2f%2fnguyentritai.tk%2fposts%2f2021%2fdepthwise-separable-convolution%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Depthwise Separable Convolution - How does it works? on telegram"
        href="https://telegram.me/share/url?text=Depthwise%20Separable%20Convolution%20-%20How%20does%20it%20works%3f&amp;url=https%3a%2f%2fnguyentritai.tk%2fposts%2f2021%2fdepthwise-separable-convolution%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

    </footer>

    <div id="comments"></div>


<script>
    function getTheme() {
        const light = "github-light"
        const dark = "github-dark"
        if (localStorage.getItem("pref-theme") === "light") {
            return light;
        } else {
            return dark;
        }
    }

    function loadUtterances() {
        const commentsContainer = document.getElementById("comments");
        if (commentsContainer !== null) {
            commentsContainer.innerHTML = ''
            const utterancesScript = document.createElement("script");
            utterancesScript.setAttribute("id", "utterances");
            utterancesScript.setAttribute("src", "https://utteranc.es/client.js");
            utterancesScript.setAttribute("repo", "nguyentritai2906/nguyentritai2906.github.io");
            utterancesScript.setAttribute("issue-term", "pathname");
            utterancesScript.setAttribute("theme", getTheme());
            utterancesScript.setAttribute("crossorigin", "anonymous");
            utterancesScript.setAttribute("async", "true");

            commentsContainer.appendChild(utterancesScript);
        }
    }

    loadUtterances();
</script>

</article>
    </main>
    <footer class="footer">
    <span>&copy; 2022 <a href="https://nguyentritai.tk/">Nguyen Tri Tai</a></span>
    <span>&middot;</span>
    <span>Powered by <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a></span>
    <span>&middot;</span>
    <span>Theme <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>

<script>
    window.onload = function() {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }

    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function(e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function() {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
            const message = {
                type: 'set-theme',
                theme: 'github-light'
            };
            var utterances = document.querySelector('iframe');
            utterances.contentWindow.postMessage(message, 'https://utteranc.es');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
            const message = {
                type: 'set-theme',
                theme: 'github-dark'
            };
            var utterances = document.querySelector('iframe');
            utterances.contentWindow.postMessage(message, 'https://utteranc.es');
        }
    })
</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) {};
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
